// Auto-generated by oag â€” do not edit
import type {

  CreateChatCompletionStreamEvent,

  CreateChatCompletionStreamStreamEvent,

} from "./types";
import { streamSse, type SSEOptions } from "./sse";

/** Options for API requests. */
export interface RequestOptions {
  signal?: AbortSignal;
  headers?: Record<string, string>;
}

/** Configuration for the API client. */
export interface ClientConfig {
  baseUrl: string;
  headers?: Record<string, string>;
  fetch?: typeof globalThis.fetch;
  requestInterceptor?: (request: { url: string; init: RequestInit }) =>
    { url: string; init: RequestInit } | Promise<{ url: string; init: RequestInit }>;
}

/** API client for AI Chat API. */
export class ApiClient {
  private readonly baseUrl: string;
  private readonly headers: Record<string, string>;
  private readonly fetchFn: typeof globalThis.fetch;
  private readonly requestInterceptor?: ClientConfig["requestInterceptor"];

  constructor(config: ClientConfig) {
    this.baseUrl = config.baseUrl.replace(/\/$/, "");
    this.headers = config.headers ?? {};
    this.fetchFn = config.fetch ?? globalThis.fetch.bind(globalThis);
    this.requestInterceptor = config.requestInterceptor;
  }

  private async request<T>(
    method: string,
    path: string,
    options?: RequestOptions & { body?: unknown; query?: Record<string, string> },
  ): Promise<T> {
    let url = `${this.baseUrl}${path}`;
    if (options?.query) {
      const params = new URLSearchParams();
      for (const [key, value] of Object.entries(options.query)) {
        if (value !== undefined && value !== null) {
          params.set(key, value);
        }
      }
      const qs = params.toString();
      if (qs) url += `?${qs}`;
    }

    let req = {
      url,
      init: {
        method,
        headers: {
          "Content-Type": "application/json",
          ...this.headers,
          ...options?.headers,
        } as Record<string, string>,
        body: options?.body !== undefined ? JSON.stringify(options.body) : undefined,
        signal: options?.signal,
      } as RequestInit,
    };

    if (this.requestInterceptor) {
      req = await this.requestInterceptor(req);
    }

    const response = await this.fetchFn(req.url, req.init);

    if (!response.ok) {
      throw new Error(`API request failed: ${response.status} ${response.statusText}`);
    }

    if (response.status === 204) {
      return undefined as T;
    }

    return response.json() as Promise<T>;
  }



  /** List available models */



  async listModels(options?: RequestOptions): Promise<{ data: { id: string; name: string; provider: string; maxTokens?: number; capabilities?: string[] }[] }> {

    const path = "/models";

    return this.request<{ data: { id: string; name: string; provider: string; maxTokens?: number; capabilities?: string[] }[] }>("GET", path, {


      ...options,
    });
  }




  /** Get a specific model */



  async getModel(modelId: string, options?: RequestOptions): Promise<{ id: string; name: string; provider: string; maxTokens?: number; capabilities?: string[] }> {

    let path = "/models/{modelId}";

    path = path.replace("{modelId}", encodeURIComponent(String(modelId)));


    return this.request<{ id: string; name: string; provider: string; maxTokens?: number; capabilities?: string[] }>("GET", path, {


      ...options,
    });
  }




  /** Creates a completion for the chat messages. Supports both JSON and streaming responses. */



  async *createChatCompletionStream(body: { model: string; messages: { role: string; content: string }[]; temperature?: number; maxTokens?: number; stream?: boolean }, options?: SSEOptions): AsyncGenerator<CreateChatCompletionStreamEvent> {

    const path = "/chat/completions";

    const url = `${this.baseUrl}${path}`;
    yield* streamSse<CreateChatCompletionStreamEvent>(url, {
      method: "POST",

      body: JSON.stringify(body),

      headers: { ...this.headers, ...options?.headers },
    }, options, this.requestInterceptor);
  }




  /** Creates a completion for the chat messages. Supports both JSON and streaming responses. */



  async createChatCompletion(body: { model: string; messages: { role: string; content: string }[]; temperature?: number; maxTokens?: number; stream?: boolean }, options?: RequestOptions): Promise<{ id: string; model: string; choices: { index: number; message: { role: string; content: string }; finishReason: string }[]; usage: { promptTokens: number; completionTokens: number; totalTokens: number } }> {

    const path = "/chat/completions";

    return this.request<{ id: string; model: string; choices: { index: number; message: { role: string; content: string }; finishReason: string }[]; usage: { promptTokens: number; completionTokens: number; totalTokens: number } }>("POST", path, {

      body,


      ...options,
    });
  }




  /** Creates a streaming chat completion. SSE-only endpoint. */



  async *createChatCompletionStream(body: { model: string; messages: { role: string; content: string }[]; temperature?: number; maxTokens?: number; stream?: boolean }, options?: SSEOptions): AsyncGenerator<CreateChatCompletionStreamStreamEvent> {

    const path = "/chat/completions/stream";

    const url = `${this.baseUrl}${path}`;
    yield* streamSse<CreateChatCompletionStreamStreamEvent>(url, {
      method: "POST",

      body: JSON.stringify(body),

      headers: { ...this.headers, ...options?.headers },
    }, options, this.requestInterceptor);
  }




  /** Submit feedback for a completion */



  async submitFeedback(body: { completionId: string; rating: number; comment?: string }, options?: RequestOptions): Promise<void> {

    const path = "/chat/feedback";

    await this.request<void>("POST", path, {

      body,


      ...options,
    });
  }


}